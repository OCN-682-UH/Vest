---
title: "Week13_LectureNotes"
subtitle: "Intro to models"
format: html
date: today
---

## Intro to Modeling
1. Intro to basic linear modeling
2. Viewing results in base R, broom, and modelsummary
3. Running many models at the same time with purrr
4. Intro to tidy models

```{r}
library(tidyverse)
library(here)
library(palmerpenguins)
library(broom)
library(performance) 
library(modelsummary)
library(tidymodels)
library(pandoc)
```

### Anatomy of a basic linear model
*simple linear model* use the following formula:

mod<-lm(y~x, data = df)

lm = linear model 
y = dependent variable 
x = independent variable(s) 
df = dataframe.

You read this as y is a function of x

*Multiple regression*
mod<-lm(y~x1 + x2, data = df)

*Interaction term*
mod<-lm(y~x1*x2, data = df) the 
* will compute x1+x2+x1:x2
```{r}
# Linear model of Bill depth ~ Bill length by species
Peng_mod<-lm(bill_length_mm ~ bill_depth_mm*species, data = penguins)
```
Asking if the slope changes based on species

#### but wait!
We need to know if our model and date fit the assumptions. Great news is there's a {performance} package for this
```{r}
check_model(Peng_mod) # check assumptions of an lm model
```
****wut does dis mean?

### View results
ANOVA
```{r}
anova(Peng_mod)
```
This is telling you if bill length and bill depth show difference (i think)

Coefficients (effect size) with error
```{r}
summary(Peng_mod)
```
This p-value gives you if your effect is different from intercept or 0

#### View results with broom
```{r}
# Tidy coefficients
coeffs<-tidy(Peng_mod) # just put tidy() around it
coeffs
```
Giving the coefficients of the model

*glance* extracts R-squared, AICs, etc of the model
```{r}
# tidy r2, etc
results<-glance(Peng_mod) 
results
```

*augment* add residuals and predicted values to your original data and requires that you put both the model and data
```{r}
# tidy residuals, etc
resid_fitted<-augment(Peng_mod)
resid_fitted
```

#### Results in {modelsummary}
[{modelsummary}](https://modelsummary.com/) creates tables and plots to summarize statistical models and data in R. Includes two families of functions:

Super useful for publishing data

*Model Summary*
modelsummary: Regression tables with side-by-side models.
modelsummary_wide: Regression tables for categorical response models or grouped coefficients.
modelplot: Coefficient plots.

*Data Summary*
datasummary: Powerful tool to create (multi-level) cross-tabs and data summaries.
datasummary_balance: Balance tables with subgroup statistics and difference in means (aka “Table 1”).
datasummary_correlation: Correlation tables.
datasummary_skim: Quick overview (“skim”) of a dataset.
datasummary_df: Turn dataframes into nice tables with titles, notes, etc.

Export summary tables to word, markdown, or tex document. You can also modify the tables to make them pub quality.

Let's compare the Peng_mod with one that does not have species as an interaction term.

```{r}
# New model
Peng_mod_noX<-lm(bill_length_mm ~ bill_depth_mm, data = penguins)
#Make a list of models and name them
models<-list("Model with interaction" = Peng_mod,
             "Model with no interaction" = Peng_mod_noX)
#Save the results as a .docx
modelsummary(models, output = here("Week_13","Output","table.docx"))
```

##### Modelplot
Canned coefficient modelplots
```{r}
#install.packages(wesanderson)
library(wesanderson)
modelplot(models) +
    labs(x = 'Coefficients', 
         y = 'Term names') +
    scale_color_manual(values = wes_palette('Darjeeling1'))
```

## Combine models and purrr
Let's say you want to plot and compare lots of different models at the same time and view the results. For example, instead of using species as an interaction term, let's make an individual model for every species.

We can essentially make a set of lists that have each dataset that we want to model and use the map functions to run the same model to every dataset. We will test it step by step

First, let's call the penguin data and create a list for the data by each species. We do this using nest(). We are going to nest the data by species.

```{r}
 models<- penguins %>%
  ungroup()%>% # the penguin data are grouped so we need to ungroup them
    nest(.by = species) # nest all the data by species
models
```

```{r}
 models<- penguins %>%
  ungroup()%>% # the penguin data are grouped so we need to ungroup them
  nest(.by = species) %>% # nest all the data by species 
  mutate(fit = map(data, ~lm(bill_length_mm~body_mass_g, data = .)))
  models
```

```{r}
models$fit # shows you each of the 3 models
```

View the results. First, let's mutate the models list so that we have a tidy coefficient dataframe (using tidy()) and a tidy model results dataframe (using glance())
```{r}
 results<-models %>%
   mutate(coeffs = map(fit, tidy), # look at the coefficients
          modelresults = map(fit, glance))  # R2 and others
results
```
Next, select what we want to show and unnest it to bring it back to a dataframe
```{r}
 results<-models %>%
   mutate(coeffs = map(fit, tidy), # look at the coefficients
          modelresults = map(fit, glance)) %>% # R2 and others 
   select(species, coeffs, modelresults) %>% # only keep the results
   unnest() # put it back in a dataframe and specify which columns to unnest
```

```{r}
view(results) # view the results
```
 
## More Stats
* stats: General (lm)and generalized (glm) linear models (already loaded with base R)
* lmer : mixed effects models
* lmerTest' : getting results from lmer
* nlme : non-linear mixed effects models
* mgcv, gam : generalized additive models
* brms, rstan, and many more : Bayesian modeling
* lavaan, peicewiseSEM : Structural Equation Models
* rpart, randomForest, xgboost, and more : Machine learning models
And so many more!
[R4DS](https://r4ds.had.co.nz/model-basics.html)
[R4DS - Nest](https://r4ds.had.co.nz/many-models.html)
[more](https://www.kaylinpavlik.com/linear-regression-with-nested-data/)


#{Tidymodels}
particularly useful for machine learning style modeling.

In tidymodels you start by specifying the functional form using the parsnip package. In our case, we will use a linear regression which is coded like this:
```{r}
linear_reg()
```
Linear Regression Model Specification (regression)

Computational engine: lm

Next, we need to set the engine for what type of linear regression we are modeling. For example, we could use an OLS regression or Bayesian or several other options. We will stick with OLS.
```{r}
lm_mod<-linear_reg() %>%
  set_engine("lm")
lm_mod
```
Next we add the model_fit
```{r}
lm_mod<-linear_reg() %>%
  set_engine("lm") %>%
  fit(bill_length_mm ~ bill_depth_mm*species, data = penguins)
lm_mod
```
Lastly, we add the tidy it. And now we can pipe this into plots, etc. Nice, tidy way to model.
```{r}
lm_mod<-linear_reg() %>%
  set_engine("lm") %>%
  fit(bill_length_mm ~ bill_depth_mm*species, data = penguins) %>%
  tidy()
lm_mod
```
Pipe to plot
```{r}
lm_mod<-linear_reg() %>%
  set_engine("lm") %>%
  fit(bill_length_mm ~ bill_depth_mm*species, data = penguins) %>%
  tidy() %>%
  ggplot()+
    geom_point(aes(x = term, y = estimate))+
    geom_errorbar(aes(x = term, ymin = estimate-std.error,
                      ymax = estimate+std.error), width = 0.1 )+
  coord_flip()
lm_mod
```

HW sub salinity to light and 3 to for
library(pushoverr)
> pushover("J - the R gods request your devotion")